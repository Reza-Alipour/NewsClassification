import torch

device = 'cuda' if torch.cuda.is_available() else 'cpu'
## this weights evaluated by a preprocessing on dataset
t1_weights = [86.20689655172414, 3.35345405767941, 19.455252918287936]
t2_weights = [8.319467554076539, 12.706480304955527, 7.4183976261127595, 12.468827930174564, 9.033423667570009,
              11.286681715575622, 8.244023083264633, 6.51890482398957, 11.001100110011, 12.626262626262626, 20.0,
              21.141649048625794, 5.299417064122946, 7.782101167315175]
t3_weights = [9.469696969696969, 22.88329519450801, 11.507479861910241, 4.655493482309125, 11.312217194570136,
              10.660980810234541, 16.420361247947454, 18.281535648994517, 20.32520325203252, 33.67003367003367,
              44.24778761061947, 15.267175572519085, 54.34782608695652, 11.098779134295228, 1.7624250969333803,
              11.481056257175661, 5.417118093174431, 20.964360587002098, 2.7210884353741496, 1.7229496898690557,
              10.97694840834248, 7.4128984432913265, 3.3211557622052474]

labse_checkpoint = 'sentence-transformers/LaBSE'
xlm_checkpoint = 'xlm-roberta-large'
tokenizer_max_size = 512
batch_size = 4
each_task_epochs = 1
total_epochs = 30
